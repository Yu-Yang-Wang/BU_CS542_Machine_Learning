{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4: Neural Networks\n",
    "\n",
    "This assignment requires a working IPython Notebook installation, which you should already have. If not, please refer to the instructions in Problem Set 2.\n",
    "\n",
    "The programming part is adapted from [Stanford CS231n](http://cs231n.stanford.edu/).\n",
    "\n",
    "Total: 100 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [30pts] Problem 1: Backprop in a simple MLP\n",
    "This problem asks you to derive all the steps of the backpropagation algorithm for a simple classification network. Consider a fully-connected neural network, also known as a multi-layer perceptron (MLP), with a single hidden layer and a one-node output layer. The hidden and output nodes use an elementwise sigmoid activation function and the loss layer uses cross-entropy loss:\n",
    "<p>\n",
    "$f(z)=\\frac{1}{1+exp(-z))}$\n",
    "<br>\n",
    "$L(\\hat{y},y)=-yln(\\hat{y}) - (1-y)ln(1-\\hat{y})$\n",
    "</p>\n",
    "<p>\n",
    "The computation graph for an example network is shown below. Note that it has an equal number of nodes in the input and hidden layer (3 each), but, in general, they need not be equal. Also, to make the application of backprop easier, we show the <i>computation graph</i> which shows the dot product and activation functions as their own nodes, rather than the usual graph showing a single node for both.\n",
    "</p>\n",
    "\n",
    "<img src=\"mlpgraph.png\" style=\"height:200px;\">\n",
    "\n",
    "The forward and backward computation are given below. NOTE: We assume no regularization, so you can omit the terms involving $\\Omega$.\n",
    "\n",
    "The forward step is: \n",
    "\n",
    "<img src=\"forward.png\" style=\"width:500px;\">\n",
    "\n",
    "and the backward step is:\n",
    "\n",
    "<img src=\"backward.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down each step of the backward pass explicitly for all layers, i.e. for the loss and $k=2,1$, compute all gradients above, expressing them as a function of variables $x, y, h, W, b$. \n",
    "We start by giving some examples. We have replaced the superscript notation $u^{(i)}$ with $u^i$, and $\\odot$ stands for element-wise multiplication.\n",
    "\n",
    "$ \\nabla_{\\hat{y}}L(\\hat{y},y) =  \\nabla_{\\hat{y}}[-yln(\\hat{y}) + (1-y)ln(1-\\hat{y})] = \\frac{\\hat{y}-y}{(1-\\hat{y})\\hat{y}} = \\frac{h^2-y}{(1-h^2)h^2}$\n",
    "\n",
    "$\\nabla_{a^2} J = g \\odot f'(a^2) = g \\odot h^2(1-h^2) = h^2 - y$\n",
    "\n",
    "Next, please derive the following.\n",
    "\n",
    "<i>Hint: you should substitute the updated values for the gradient $g$ in each step and simplify as much as possible.</i>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5pts] Q1.1**: $\\nabla_{a^2}J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** `[double click here to add a solution]` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5pts] Q1.2**: $\\nabla_{b^2}J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** `[double click here to add a solution]` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5pts] Q1.3**: $\\nabla_{W^2}J$ <br><i>Hint: this should be a vector, since $W^2$ is a vector. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** `[double click here to add a solution]` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5pts] Q1.4**: $\\nabla_{h^1}J$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** `[double click here to add a solution]` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5pts] Q1.5**: $\\nabla_{b^1}J$, $\\nabla_{W^1}J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** `[double click here to add a solution]` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5pts] Q1.6** Briefly, explain how would the computational speed of backpropagation be affected if it did not include a forward pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** `[double click here to add a solution]` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [50pts] Problem 2 (Programming): Implementing a simple MLP\n",
    "In this problem we will develop a neural network with fully-connected layers, or Multi-Layer Perceptron (MLP). We will use it in classification tasks.\n",
    "\n",
    "In the current directory, you can find a file `mlp.py`, which contains the definition for class `TwoLayerMLP`. As the name suggests, it implements a 2-layer MLP, or MLP with 1 *hidden* layer. You will implement your code in the file, and call the member functions in this notebook. Below is some initialization, the `autoreload` command make sure that `mlp.py` is periodically reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlp import TwoLayerMLP\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we initialize a toy model and some toy data, the task is to classify five 4-d vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a small net and some toy data to check your implementations.\n",
    "# Note that we set the random seed for repeatable experiments.\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model(actv, std=1e-1):\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerMLP(input_size, hidden_size, num_classes, std=std, activation=actv)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "X, y = init_toy_data()\n",
    "print('X = ', X)\n",
    "print()\n",
    "print('y = ', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5pts] Q2.1 Forward pass: Sigmoid\n",
    "Our 2-layer MLP uses a softmax output layer  and the multiclass cross-entropy loss to perform classification. Both are defined in Problem Set 2.\n",
    "\n",
    "Please take a look at method `TwoLayerMLP.loss` in the file `mlp.py`. This function takes in the data and weight parameters, and computes the class scores (aka logits), the loss $L$, and the gradients on the parameters. \n",
    "\n",
    "- Complete the implementation of forward pass (up to the computation of `scores`) for the sigmoid activation: $\\sigma(x)=\\frac{1}{1+exp(-x)}$.\n",
    "\n",
    "**Note 1**: Softmax cross entropy loss involves the [log-sum-exp operation](https://en.wikipedia.org/wiki/LogSumExp). This can result in numerical underflow/overflow. Read about the solution in the link, and try to understand the calculation of `loss` in the code.\n",
    "\n",
    "**Note 2**: You're strongly encouraged to implement in a vectorized way and avoid using slower `for` loops. Note that most numpy functions support vector inputs.\n",
    "\n",
    "Check the correctness of your forward pass below. The difference should be very small (<1e-6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = init_toy_model('sigmoid')\n",
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 1.182248\n",
    "print(loss)\n",
    "print('Difference between your loss and correct loss:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10pts] Q2.2 Backward pass: Sigmoid\n",
    "- For sigmoid activation, complete the computation of `grads`, which stores the gradient of the loss with respect to the variables `W1`, `b1`, `W2`, and `b2`.\n",
    "\n",
    "Now debug your backward pass using a numeric gradient check. Again, the differences should be very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "from utils import eval_numerical_gradient\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# these should all be very small\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e'%(param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5pts] Q2.3 Train the Sigmoid network\n",
    "To train the network we will use stochastic gradient descent (SGD), implemented in `TwoLayerNet.train`. Then we train a two-layer network on toy data.\n",
    "\n",
    "- Implement the prediction function `TwoLayerNet.predict`, which is called during training to keep track of training and validation accuracy.\n",
    "\n",
    "You should get the final training loss around 0.1, which is good, but not too great for such a toy problem.  One problem is that the gradient magnitude for W1 (the first layer weights) stays small all the time, and the neural net doesn't get much \"learning signals\". This has to do with the saturation problem of the sigmoid activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = init_toy_model('sigmoid', std=1e-1)\n",
    "stats = net.train(X, y, X, y,\n",
    "                  learning_rate=0.5, reg=1e-5,\n",
    "                  num_epochs=100, verbose=False)\n",
    "print('Final training loss: ', stats['loss_history'][-1])\n",
    "\n",
    "# plot the loss history and gradient magnitudes\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['grad_magnitude_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('||W1||')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Gradient magnitude history (W1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5pts] Q2.4 Using ReLU activation\n",
    "The Rectified Linear Unit (ReLU) activation is also widely used: $ReLU(x)=max(0,x)$.\n",
    "\n",
    "- Complete the implementation for the ReLU activation (forward and backward) in `mlp.py`.\n",
    "- Train the network with ReLU, and report your final training loss.\n",
    "\n",
    "Make sure you first pass the numerical gradient check on toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = init_toy_model('relu', std=1e-1)\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "print('loss = ', loss)  # correct_loss = 1.320973\n",
    "\n",
    "# The differences should all be very small\n",
    "print('checking gradients')\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e'%(param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it's working, let's train the network. Does the net get stronger learning signals (i.e. gradients) this time? Report your final training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = init_toy_model('relu', std=1e-1)\n",
    "stats = net.train(X, y, X, y,\n",
    "                  learning_rate=0.1, reg=1e-5,\n",
    "                  num_epochs=50, verbose=False)\n",
    "\n",
    "print('Final training loss: ', stats['loss_history'][-1])\n",
    "\n",
    "# plot the loss history\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['grad_magnitude_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('||W1||')\n",
    "plt.title('Gradient magnitude history (W1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data\n",
    "Now that you have implemented a two-layer network that works on toy data, let's try some real data. The MNIST dataset is a standard machine learning benchmark. It consists of 70,000 grayscale handwritten digit images, which we split into 50,000 training, 10,000 validation and 10,000 testing. The images are of size 28x28, which are flattened into 784-d vectors.\n",
    "\n",
    "**Note 1**: the function `get_MNIST_data` requires the `scikit-learn` package. If you previously did anaconda installation to set up your Python environment, you should already have it. Otherwise, you can install it following the instructions here: http://scikit-learn.org/stable/install.html\n",
    "\n",
    "**Note 2**: If you encounter a `HTTP 500` error, that is likely temporary, just try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load MNIST\n",
    "from utils import get_MNIST_data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_MNIST_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.5 Train a network on MNIST\n",
    "We will now train a network on MNIST with 64 hidden units in the hidden layer. We train it using SGD, and decrease the learning rate with an exponential rate over time; this is achieved by multiplying the learning rate with a constant factor `learning_rate_decay` (which is less than 1) after each epoch. In effect, we are using a high learning rate initially, which is good for exploring the solution space, and using lower learning rates later to encourage convergence to a local minimum (or [saddle point](http://www.offconvex.org/2016/03/22/saddlepoints/), which may happen more often).\n",
    "\n",
    "- Train your MNIST network with 2 different activation functions: sigmoid and ReLU. \n",
    "\n",
    "We first define some variables and utility functions. The `plot_stats` function plots the hisotories of gradient magnitude, training loss, and accuracies on the training and validation sets. The `visualize_weights` function visualizes the weights learned in the first layer of the network. In most neural networks trained on visual data, the first layer weights typically show some visible structure when visualized. Both functions help you to diagnose the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "# Plot the loss function and train / validation accuracies\n",
    "def plot_stats(stats):\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(stats['grad_magnitude_history'])\n",
    "    plt.title('Gradient magnitude history (W1)')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('||W1||')\n",
    "    plt.ylim(0, np.minimum(100,np.max(stats['grad_magnitude_history'])))\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(stats['loss_history'])\n",
    "    plt.title('Loss history')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(stats['train_acc_history'], label='train') \n",
    "    plt.plot(stats['val_acc_history'], label='val')\n",
    "    plt.title('Classification accuracy history')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Clasification accuracy')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the weights of the network\n",
    "from utils import visualize_grid\n",
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.T.reshape(-1, 28, 28)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10pts] Q2.5.1 Sigmoid network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid_net = TwoLayerMLP(input_size, hidden_size, num_classes, activation='sigmoid', std=1e-1)\n",
    "\n",
    "# Train the network\n",
    "sigmoid_stats = sigmoid_net.train(X_train, y_train, X_val, y_val, \n",
    "                                  num_epochs=20, batch_size=100, \n",
    "                                  learning_rate=1e-3,  learning_rate_decay=0.95, \n",
    "                                  reg=0.5, verbose=True)\n",
    "\n",
    "# Predict on the training set\n",
    "train_acc = (sigmoid_net.predict(X_train) == y_train).mean()\n",
    "print('Sigmoid final training accuracy: ', train_acc)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_acc = (sigmoid_net.predict(X_val) == y_val).mean()\n",
    "print('Sigmoid final validation accuracy: ', val_acc)\n",
    "\n",
    "# Predict on the test set\n",
    "test_acc = (sigmoid_net.predict(X_test) == y_test).mean()\n",
    "print('Sigmoid test accuracy: ', test_acc)\n",
    "\n",
    "# show stats and visualizations\n",
    "plot_stats(sigmoid_stats)\n",
    "show_net_weights(sigmoid_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10pts] Q2.5.2 ReLU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relu_net = TwoLayerMLP(input_size, hidden_size, num_classes, activation='relu', std=1e-1)\n",
    "\n",
    "# Train the network\n",
    "relu_stats = relu_net.train(X_train, y_train, X_val, y_val, \n",
    "                            num_epochs=20, batch_size=100,\n",
    "                            learning_rate=1e-3, learning_rate_decay=0.95, \n",
    "                            reg=0.5, verbose=True)\n",
    "# Predict on the training set\n",
    "train_acc = (relu_net.predict(X_train) == y_train).mean()\n",
    "print('ReLU final training accuracy: ', train_acc)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_acc = (relu_net.predict(X_val) == y_val).mean()\n",
    "print('ReLU final validation accuracy: ', val_acc)\n",
    "\n",
    "# Predict on the test set\n",
    "test_acc = (relu_net.predict(X_test) == y_test).mean()\n",
    "print('ReLU test accuracy: ', test_acc)\n",
    "\n",
    "# show stats and visualizations\n",
    "plot_stats(relu_stats)\n",
    "show_net_weights(relu_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### [5pts] Q2.5.3 \n",
    "\n",
    "Which activation function would you choose in practice? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20pts] Problem 3: Simple Regularization Methods\n",
    "You may have noticed the `reg` parameter in `TwoLayerMLP.loss`, controlling \"regularization strength\". In learning neural networks, aside from minimizing a loss function $\\mathcal{L}(\\theta)$ with respect to the network parameters $\\theta$, we usually explicitly or implicitly add some regularization term to reduce overfitting. A simple and popular regularization strategy is to penalize some *norm* of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10pts] Q3.1:  L2 regularization\n",
    "\n",
    "We can penalize the L2 norm of $\\theta$: we modify our objective function to be $\\mathcal{L}(\\theta) + \\lambda \\|\\theta\\|^2$ where $\\lambda$ is the weight of regularization. \n",
    "We will minimize this objective using gradient descent with step size $\\eta$.\n",
    "Derive the update rule: at time $t+1$, express the new parameters $\\theta_{t+1}$ in terms of the old parameters $\\theta_t$, the gradient $g_t=\\frac{\\partial \\mathcal{L}}{\\partial \\theta_t}$, $\\eta$, and $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Double click here to add your answer]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10pts] Q3.2:  L1 regularization\n",
    "\n",
    "Now let's consider L1 regularization: our objective in this case is $\\mathcal{L}(\\theta) + \\lambda \\|\\theta\\|_1$. Derive the update rule. \n",
    "\n",
    "(Technically this becomes *Sub-Gradient* Descent since the L1 norm is not differentiable at 0. But practically it is usually not an issue.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Double click here to add your answer]**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
